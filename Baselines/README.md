# Baselines for comparison
The details of three-class implementation of the baselines can be found in `Section V.A` of the paper </br>

1. MC-EffNet [1] : :balance_scale: https://github.com/manjaryp/GANvsGraphicsvsReal </br>
2. InceptionResNet [2] : :balance_scale: [inceptionresnet.py](https://github.com/manjaryp/GANvsGraphicsvsReal/blob/main/Baselines/inceptionresnet.py) </br>
3. Quan et al. [3] : :balance_scale: https://github.com/weizequan/NIvsCG or </br>
https://github.com/Nx2018/Computer-Generated-image-detection/tree/master/tifs </br>
4. Nataraj et al. [4] : :balance_scale: [natraj_gan_baseline.py](https://github.com/manjaryp/GANvsGraphicsvsReal/blob/main/Baselines/natraj_gan_baseline.py)
5. Rezende et al. [5] : :balance_scale: https://github.com/bazinho/CG </br>

## References
[1] Manjary P. Gangan, Anoop K., Lajish V. L., "Distinguishing natural and computer generated images using Multi-Colorspace fused EfficientNet", Journal of Information Security and Applications, Elsevier, Volume 68, 2022, 103261, ISSN 2214-2126, https://doi.org/10.1016/j.jisa.2022.103261. </br>
[2] Szegedy, Christian, Sergey Ioffe, Vincent Vanhoucke, and Alexander A. Alemi. "Inception-v4, inception-resnet and the impact of residual connections on learning." In Thirty-first AAAI conference on artificial intelligence. 2017. </br>
[3] Quan, Weize, Kai Wang, Dong-Ming Yan, and Xiaopeng Zhang. "Distinguishing between natural and computer-generated images using convolutional neural networks." IEEE Transactions on Information Forensics and Security 13, no. 11 (2018): 2772-2787. </br>
[4] Nataraj, Lakshmanan, Tajuddin Manhar Mohammed, B. S. Manjunath, Shivkumar Chandrasekaran, Arjuna Flenner, Jawadul H. Bappy, and Amit K. Roy-Chowdhury. "Detecting GAN generated fake images using co-occurrence matrices." Electronic Imaging 2019, no. 5 (2019): 532-1. </br>
[5] De Rezende, Edmar RS, Guilherme CS Ruppert, Antonio Theophilo, Eric K. Tokuda, and Tiago Carvalho. "Exposing computer generated images by using deep convolutional neural networks." Signal Processing: Image Communication 66 (2018): 113-126. </br>
